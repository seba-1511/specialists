# Based on the Maxout Network for PyLearn2
# To try:
# - batch normalization
# - 785 epochs
# - momentum start and finish
# - Weight decay with gdm
# - schedule learning rate

!obj:experiments.FitPredictErrorExperiment {
    dataset: &ds !obj:datasets.CIFAR100 {
        repo_path: '~/data',
        sample_pct: 100,
        coarse: False,
    },
    
  metrics: {
        train: [
            !obj:metrics.MisclassPercentage {error_rank: 1},
            !obj:metrics.MisclassPercentage {error_rank: 5},
        ],
        test: [
            !obj:metrics.MisclassPercentage {}
        ]
    },

  weight_inits: &wt_init !obj:params.UniformValGen {
      low: 0.005,
      high: 0.005,
      bias_init: 0.05,
    },

  weight_inits: &wt_init0 !obj:params.GaussianValGen {
      scale: .01,
      bias_init: 0.05,
    },

  lrule: &gdm {
      type: gradient_descent_momentum,
      lr_params: {
          learning_rate: 0.3,
          momentum_params: {
              type: constant,
              coef: 0.5,
            },
        },
    },
  
  
  model: !obj:models.MLP {
      num_epochs: 15,
      batch_size: &bs 256,
      batch_norm: True,
      #serialized_path: '~/saved_models/specialists/exp_cifar.prm',
      layers: [
          &datalayer !obj:layers.DataLayer {
              name: d0,
              is_local: True,
              nofm: 3,
              ofmshape: [32, 32],
            },
            !obj:layers.ConvLayer {
                name: conv1,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nofm: 128,
                fshape: [8, 8],
                activation: !obj:transforms.RectLin {},
                pad: 4,
            },
            !obj:layers.PoolingLayer {
                name: pool2,
                op: 'max',
                fshape: [4, 4],
                stride: 2,
            },
            !obj:layers.DropOutLayer {
                name: dropout1,
                keep: 0.8,
            },
            !obj:layers.ConvLayer {
                name: conv4,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nofm: 192,
                fshape: [8, 8],
                activation: !obj:transforms.RectLin {},
                pad: 3,
            },
            !obj:layers.PoolingLayer {
                name: pool5,
                op: 'max',
                fshape: [4, 4],
                stride: 2,
            },
            !obj:layers.ConvLayer {
                name: conv6,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nofm: 192,
                fshape: [5, 5],
                activation: !obj:transforms.RectLin {},
                pad: 3,
            },
            !obj:layers.PoolingLayer {
                name: pool7,
                op: 'max',
                fshape: [2, 2],
                stride: 2,
            },
            #!obj:layers.FCLayer {
                #name: layer6,
                #nout: 500,
                #lrule_init: *gdm,
                #weight_init: *wt_init,
                #activation: !obj:transforms.RectLin {},
            #},
            !obj:layers.FCLayer {
                name: layer7,
                nout: 500,
                lrule_init: *gdm,
                weight_init: *wt_init,
                activation: !obj:transforms.RectLin {},
            },
            &lastlayer !obj:layers.FCLayer {
                name: output,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nout: 100,
                activation: !obj:transforms.Logistic {},
            },
            &costlayer !obj:layers.CostLayer {
                name: cost,
                ref_layer: *datalayer,
                cost: !obj:transforms.CrossEntropy {},
            },
        ],
    },

    logging: {
        level: 20,
        format: '%(asctime)-15s %(levelname)s:%(module)s - %(message)s'
    },
}
