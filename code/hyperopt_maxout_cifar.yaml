# Based on the Maxout Network for PyLearn2

!obj:experiments.FitPredictErrorExperiment {
    return_item: test,
    dataset: &ds !obj:datasets.CIFAR100 {
        repo_path: '~/data',
    sample_pct: 100
},

  metrics: {
        train: [
            !obj:metrics.MisclassPercentage {}
        ],
        test: [
            !obj:metrics.MisclassPercentage {}
        ]
    },

  weight_inits: &wt_init !obj:params.UniformValGen {
      low: !hyperopt W_init_low FLOAT -1.0 0.0,
      high: !hyperopt W_init_high FLOAT 0.0 1.0,
    },

  weight_inits: &wt_init0 !obj:params.GaussianValGen {
      scale: .01,
      bias_init: 0.0,
    },

  lrule: &gdm {
      type: gradient_descent_momentum,
      lr_params: {
          learning_rate: !hyperopt gdm_lr FLOAT 0.001 0.5,
          momentum_params: {
              type: nesterov,
              coef: !hyperopt lr_momentum FLOAT 0.1 0.99,
            },
        },
    },
  
  
  model: !obj:models.MLP {
      num_epochs: 74,
      batch_size: &bs 128,
      layers: [
          &datalayer !obj:layers.DataLayer {
              name: d0,
              is_local: True,
              nofm: 3,
              ofmshape: [32, 32],
            },
            !obj:layers.ConvLayer {
                name: layer1,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nofm: 96,
                fshape: [8, 8],
                activation: !obj:transforms.RectLin {},
            },
            !obj:layers.PoolingLayer {
                name: layer2,
                op: 'max',
                fshape: [4, 4],
                stride: 2,
            },
            !obj:layers.DropOutLayer {
                name: dropout1,
                keep: !hyperopt drop1 FLOAT 0.0 1.0,
            },
            !obj:layers.ConvLayer {
                name: layer4,
                lrule_init: *gdm,
                nofm: 192,
                fshape: [8, 8],
                weight_init: *wt_init,
            },
            !obj:layers.PoolingLayer {
                name: layer5,
                op: 'max',
                fshape: [4, 4],
                stride: 2,
            },
            !obj:layers.FCLayer {
                name: layer6,
                nout: 500,
                lrule_init: *gdm,
                weight_init: *wt_init,
                activation: !obj:transforms.RectLin {},
            },
            &lastlayer !obj:layers.FCLayer {
                name: output,
                lrule_init: *gdm,
                weight_init: *wt_init,
                nout: 100,
                activation: !obj:transforms.Logistic {},
            },
            &costlayer !obj:layers.CostLayer {
                name: cost,
                ref_layer: *datalayer,
                cost: !obj:transforms.CrossEntropy {},
            },
        ],
    },

# logging options that are passed to logging.basicConfig
# level value thresholds (set level lower to display them):
#   CRITICAL 50
#   ERROR    40
#   WARNING  30
#   INFO     20
#   DEBUG    10
#   NOTSET    0
    logging: {
        level: 20,
        format: '%(asctime)-15s %(levelname)s:%(module)s - %(message)s'
    },
}
